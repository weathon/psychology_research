{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recorded Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMklWZoxrlcD81pS38gJPf4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/psychology_research/blob/master/Recorded_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O02d3u8d-I88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a76c01c2-069f-4215-de7e-19850d515a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-09 02:44:46--  https://mdpi-res.com/d_attachment/data/data-04-00124/article_deploy/data-04-00124-s001.zip\n",
            "Resolving mdpi-res.com (mdpi-res.com)... 172.67.68.164, 104.26.14.90, 104.26.15.90, ...\n",
            "Connecting to mdpi-res.com (mdpi-res.com)|172.67.68.164|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1134038 (1.1M) [application/zip]\n",
            "Saving to: ‘data-04-00124-s001.zip’\n",
            "\n",
            "data-04-00124-s001. 100%[===================>]   1.08M  1.48MB/s    in 0.7s    \n",
            "\n",
            "2022-05-09 02:44:47 (1.48 MB/s) - ‘data-04-00124-s001.zip’ saved [1134038/1134038]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://mdpi-res.com/d_attachment/data/data-04-00124/article_deploy/data-04-00124-s001.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv data-04-00124-s001.zip data.zip\n",
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "-kpc3uRA-NOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3087496b-1492-4ce3-a40c-5571bb5cf691"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "  inflating: data.csv                \n",
            "  inflating: Questionnaire1.pdf      \n",
            "  inflating: Questionnaire2.pdf      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install numpy -U\n",
        "# !pip install --upgrade scipy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats"
      ],
      "metadata": {
        "id": "ynG4Qi7k-O_0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrame = pd.read_csv(\"data.csv\")"
      ],
      "metadata": {
        "id": "IpSoBfal-QKF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Grad = DataFrame[DataFrame[\"Academic\"] == \"Grad\"]"
      ],
      "metadata": {
        "id": "yNKBmXxS-hZN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Under = DataFrame[DataFrame[\"Academic\"] == \"Under\"]"
      ],
      "metadata": {
        "id": "2TpVF3ZQ-jyt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(Grad[\"ToDep\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCV8T1wW-q-u",
        "outputId": "6e0d3771-e72a-4818-dac1-3f43073ed781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.285714285714286"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(Under[\"ToDep\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf3FIWO9-vPN",
        "outputId": "facb12c5-406b-4b63-9110-c07b9a31e6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.433198380566802"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.std(Grad[\"ToDep\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeAfkXOFiZEH",
        "outputId": "f3b4a4f5-0481-43a7-cf70-325d9236738e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.587582514635688"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.std(Under[\"ToDep\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIMLOfdhiYEj",
        "outputId": "54374efc-4d91-41b5-c658-eeaaa46138ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.966547107923175"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.stats.ttest_ind(Grad[\"ToDep\"],Under[\"ToDep\"],equal_var=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCqm7_TYN761",
        "outputId": "0e90a7ad-f31c-4896-c21c-e2e4345360f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=-3.6494976679191113, pvalue=0.0011254856725920373)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot([Under[\"ToDep\"],Grad[\"ToDep\"]],labels=[\"Undergrad\",\"Grad\"])\n",
        "plt.title(\"Box Plot of Total Depression Score\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "c2I7eyYUp4mo",
        "outputId": "6341eb51-ad26-4fb2-89f6-8985786aa3b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Box Plot of Total Depression Score')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrame.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts933-Kzq-nf",
        "outputId": "83e11bbf-5bd6-4633-fcaf-9c753b27465a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['inter_dom', 'Region', 'Gender', 'Academic', 'Age', 'Age_cate', 'Stay',\n",
              "       'Stay_Cate', 'Japanese', 'Japanese_cate', 'English', 'English_cate',\n",
              "       'Intimate', 'Religion', 'Suicide', 'Dep', 'DepType', 'ToDep', 'DepSev',\n",
              "       'ToSC', 'APD', 'AHome', 'APH', 'Afear', 'ACS', 'AGuilt', 'AMiscell',\n",
              "       'ToAS', 'Partner', 'Friends', 'Parents', 'Relative', 'Profess',\n",
              "       ' Phone', 'Doctor', 'Reli', 'Alone', 'Others', 'Internet', 'Partner_bi',\n",
              "       'Friends_bi', 'Parents_bi', 'Relative_bi', 'Professional_bi',\n",
              "       'Phone_bi', 'Doctor_bi', 'religion_bi', 'Alone_bi', 'Others_bi',\n",
              "       'Internet_bi'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrame[\"Intimate\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbZJHFQx4tpL",
        "outputId": "ab3a1e4a-b76a-4b8e-dc56-8efc04ada920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      NaN\n",
              "1      NaN\n",
              "2      Yes\n",
              "3       No\n",
              "4      Yes\n",
              "      ... \n",
              "281    NaN\n",
              "282    NaN\n",
              "283    NaN\n",
              "284    NaN\n",
              "285    NaN\n",
              "Name: Intimate, Length: 286, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def isnan(v):\n",
        "  if type(v) == str: #not strkoukeyahcikun\n",
        "    return False\n",
        "  else:\n",
        "    return math.isnan(v)"
      ],
      "metadata": {
        "id": "hT4WhzSg7GcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LoBzbDGc4TEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Intimate"
      ],
      "metadata": {
        "id": "LUVBGkzz71ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLrvAdy27Ca9",
        "outputId": "42f0815e-5b30-403b-b85a-adf7a8df564b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scipy.stats.ttest_ind(DataFrame[DataFrame[\"Internet_bi\"] == \"Yes\"][\"ToDep\"],DataFrame[DataFrame[\"Internet_bi\"] == \"No\"][\"ToDep\"],equal_var=1)\n",
        "scipy.stats.ttest_ind(DataFrame[DataFrame[\"Internet_bi\"] == \"Yes\"][\"ToDep\"],DataFrame[DataFrame[\"Internet_bi\"] == \"No\"][\"ToDep\"],equal_var=0) #Smaller?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o-wrNxCrBuO",
        "outputId": "8ad3fce0-8b4f-4b50-ce32-658d8cde943b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=1.9182171986253846, pvalue=0.05916582875673046)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.std(DataFrame[DataFrame[\"Friends_bi\"] == \"Yes\"][\"ToDep\"]),np.std(DataFrame[DataFrame[\"Friends_bi\"] == \"No\"][\"ToDep\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvGsdBQ3sXqJ",
        "outputId": "560ee13e-3d7c-4b65-d018-0c5128dcf8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.457365031870707 5.224251728472603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(DataFrame[DataFrame[\"Gender\"] == \"Male\"][\"ToDep\"]),np.mean(DataFrame[DataFrame[\"Gender\"] == \"Female\"][\"ToDep\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbiJWr_Psmja",
        "outputId": "9fea398c-f8d0-4d4a-8622-5db231894190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.816326530612245 8.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot([DataFrame[DataFrame[\"English_cate\"] == \"High\"][\"ToDep\"],DataFrame[DataFrame[\"English_cate\"] == \"Low\"][\"ToDep\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "vwJSEk0lsugV",
        "outputId": "219c072c-4cc6-48e7-db7a-31228819fec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7f2803f6cb90>,\n",
              "  <matplotlib.lines.Line2D at 0x7f2803e97290>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7f2803ec0510>,\n",
              "  <matplotlib.lines.Line2D at 0x7f2803fd0ed0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f2803f3fa50>,\n",
              "  <matplotlib.lines.Line2D at 0x7f2803e3d550>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7f2803e6bc50>,\n",
              "  <matplotlib.lines.Line2D at 0x7f2803e44250>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7f2803e76250>,\n",
              "  <matplotlib.lines.Line2D at 0x7f2803e3d190>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7f2804057150>,\n",
              "  <matplotlib.lines.Line2D at 0x7f280626a350>,\n",
              "  <matplotlib.lines.Line2D at 0x7f2803ec4190>,\n",
              "  <matplotlib.lines.Line2D at 0x7f2804097290>]}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.stats.ttest_ind(DataFrame[DataFrame[\"English_cate\"] == \"High\"][\"ToAS\"],DataFrame[DataFrame[\"English_cate\"] == \"Low\"][\"ToAS\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZuubwxxsJuX",
        "outputId": "2a8a6a96-e6d1-488d-bb14-62f4472de377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=1.3583776554393088, pvalue=0.17598912821951992)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.stats.ttest_ind(DataFrame[DataFrame[\"Gender\"] == \"Male\"][\"ToAS\"],DataFrame[DataFrame[\"Gender\"] == \"Female\"][\"ToAS\"],equal_var=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2kR7meYtt4z",
        "outputId": "70e36c8c-47b4-432a-b9dc-f261abe7b4ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=-1.8707914723192378, pvalue=0.06274958281051941)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrame.Internet_bi.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYxVG59OrIMo",
        "outputId": "acf98ca2-fdf1-4000-ce77-015e47fad29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No     223\n",
              "Yes     45\n",
              "45       2\n",
              "223      2\n",
              "Name: Internet_bi, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(DataFrame[\"Stay\"],DataFrame[\"Afear\"],alpha=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "deiKhBSh3SIz",
        "outputId": "ad8e97d4-c053-4bf3-fd25-0d3913bc2aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f280983cfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "2ZZyOzrs4dbS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = DataFrame#[DataFrame[\"Stay\"]<=6]\n",
        "x = np.array([[value for value in df2[\"Afear\"] if not math.isnan(value)]]).reshape(-1,1)\n",
        "y = [value for value in df2[\"ToDep\"] if not math.isnan(value)]\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression().fit(x, y)\n",
        "\n",
        "xs = np.arange(2.5,17.5,0.2)\n",
        "plt.scatter(x, y,alpha=0.1)\n",
        "plt.plot(xs, xs*reg.coef_[0]+reg.intercept_)\n",
        "plt.title(\"Correlation Between Fear And Depression\")\n",
        "plt.xlabel(\"Total ASISS Fear Score\")\n",
        "plt.ylabel(\"Total PHQ-9\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "RLCKBXnM4ve7",
        "outputId": "424fdaa0-3b8e-4b7e-d243-6dcf8a1af7fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Total PHQ-9')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.stats.spearmanr(x,y) #RESULT OF Spearman’s"
      ],
      "metadata": {
        "id": "8xx7M11styP-",
        "outputId": "2186f14f-9e4e-497e-81b9-f0e90bde3352",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpearmanrResult(correlation=0.3907004185267795, pvalue=3.320828877072475e-11)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "3.320828877072475e-11*2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QksaKNlAIb-",
        "outputId": "4bd5324e-39cb-4c7c-b499-06dae0225763"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.64165775414495e-11"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6L3MVhv53zT",
        "outputId": "a00030bf-be91-445e-db58-e53fb179a04d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.29607538])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y).shape"
      ],
      "metadata": {
        "id": "iwAtLoLC_PZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d5039a-744a-414e-cff2-554c029bd7a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(268,)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ret = scipy.stats.linregress(x.reshape(-1),np.array(y))#ereshape -1 bushi 1 -1 eixnchoahuangberen exinkoukeyahci bieren dianhuaynpi"
      ],
      "metadata": {
        "id": "tWm8sWbg-lje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHyMqwDHBck7",
        "outputId": "2de14530-1df1-4449-8fc5-6ab9acaa8662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinregressResult(slope=-0.20510417417633964, intercept=8.935044337106195, rvalue=-0.03645150913166049, pvalue=0.5524150412502756, stderr=0.3447699844580074)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "alHDtTBVBq6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slope,reg.coef_#koukequeshiyiyang"
      ],
      "metadata": {
        "id": "EucVC_NO-xU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "std_err#yanpi zhege r buyiyang r ^2 yanpi "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "GMTWrhnO-5ED",
        "outputId": "909adc26-4110-434b-e61e-3a7d814d07c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-cd65c9291177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstd_err\u001b[0m\u001b[0;31m#yanpi zhege r buyiyang r ^2 yanpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'std_err' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrame[\"Dep\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l_scXRAbXV-",
        "outputId": "264f0ed0-5655-48c8-8d3f-f7de2e9de969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No     172\n",
              "Yes     96\n",
              "96       1\n",
              "172      1\n",
              "Name: Dep, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UnderOberseved = Under[\"Dep\"].value_counts()[\"Yes\"]\n",
        "GradOberseved = Grad[\"Dep\"].value_counts()[\"Yes\"]\n",
        "UnderExp = DataFrame[\"Dep\"].value_counts()[\"Yes\"]/len(DataFrame) * len(Under)\n",
        "GradExp = DataFrame[\"Dep\"].value_counts()[\"Yes\"]/len(DataFrame) * len(Grad)"
      ],
      "metadata": {
        "id": "8aItCAJHcm8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(UnderOberseved,UnderExp)\n",
        "print(GradOberseved,GradExp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeK6qCsRdDG0",
        "outputId": "e9c2e404-7119-4373-a646-76080a9e8d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91 82.9090909090909\n",
            "5 7.048951048951049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.stats.chisquare([UnderOberseved, GradOberseved],[UnderExp, GradExp])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ-SzX8EdkD5",
        "outputId": "7a1c8d80-5173-490f-b902-303a760c4a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Power_divergenceResult(statistic=1.2736769554395033, pvalue=0.2590780172847901)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.stats.mannwhitneyu(Under[\"ToDep\"],Grad[\"ToDep\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGV-9cxYgMxs",
        "outputId": "39bed51b-8b1e-42e0-e892-f8ac2c20bf7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MannwhitneyuResult(statistic=1607.5, pvalue=0.0018835062946156987)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.stats.mannwhitneyu(DataFrame[DataFrame[\"Intimate\"] == \"Yes\"][\"ToDep\"],DataFrame[DataFrame[\"Intimate\"] == \"No\"][\"ToDep\"]) #huxiyachhizhangkuntt zhege juranmeiyou xianggunaxng??"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvdXjfUf5ijS",
        "outputId": "62fdf1a8-9bcc-4fb7-fbe2-a8202447c58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MannwhitneyuResult(statistic=7560.0, pvalue=0.1874197953619176)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(DataFrame[DataFrame[\"Intimate\"] == \"Yes\"][\"ToDep\"],bins=np.arange(0,25))\n",
        "plt.title(\"Hist Of Undergrad Student\")\n",
        "plt.xlabel(\"PHQ-9 Score\")\n",
        "plt.ylabel(\"Number of People\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "kGwHJ4sAj4JE",
        "outputId": "f0c333a3-e211-4522-fdde-0a4d60390746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Number of People')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(DataFrame[DataFrame[\"Intimate\"] == \"No\"][\"ToDep\"],bins=np.arange(0,25))\n",
        "plt.title(\"Hist Of Grad Student\")\n",
        "plt.xlabel(\"PHQ-9 Score\")\n",
        "plt.ylabel(\"Number of People\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "dwhYxMepj7cb",
        "outputId": "f14aa39e-a07b-44bb-f1dc-b770079016d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Number of People')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EJdIZZjrJ2M",
        "outputId": "448a5866-82f4-4c51-8455-4183c39c4d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpearmanrResult(correlation=0.03215543517949416, pvalue=0.6002213889680279)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.version.full_version # scipy evrsion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fuQPPKfwuwXt",
        "outputId": "36b986a4-5114-43b8-a070-245fd7223730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.21.6'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.version.full_version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MWJeSpM5vvcl",
        "outputId": "4efc64de-f111-482c-c7e5-071d31ed74ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.7.3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "InPutNum = [\"Japanese\",\"English\",\"Age\",\"Stay\"]\n",
        "InPutCat = [\"Intimate\",\"Gender\",\"inter_dom\",\"Religion\",\"Academic\"]\n",
        "# DataFrame[InPutCat]\n",
        "newData = {}\n",
        "newData[\"Intimate\"] = DataFrame[\"Intimate\"].replace(\"Yes\",1).replace(\"No\",0).replace(math.nan,-1) #zhegebuhaomakunduzitthl\n",
        "newData[\"Gender\"] = DataFrame[\"Gender\"].replace(\"Male\",1).replace(\"Female\",0).replace(math.nan,-1)\n",
        "newData[\"inter_dom\"] = DataFrame[\"inter_dom\"].replace(\"Inter\",1).replace(\"Dom\",0).replace(math.nan,-1)\n",
        "newData[\"Religion\"] = DataFrame[\"Religion\"].replace(\"Yes\",1).replace(\"No\",0).replace(math.nan,-1)\n",
        "newData[\"Academic\"] = DataFrame[\"Academic\"].replace(\"Under\",1).replace(\"Grad\",0).replace(math.nan,-1)\n",
        "newData[\"Japanese\"] = DataFrame[\"Japanese\"].replace(math.nan,-1)\n",
        "newData[\"English\"] = DataFrame[\"English\"].replace(math.nan,-1)\n",
        "newData[\"Age\"] = DataFrame[\"Age\"].replace(math.nan,-1)\n",
        "newData[\"Stay\"] = DataFrame[\"Stay\"].replace(math.nan,-1)\n",
        "\n",
        "# X = np.array([Japanese,English,Age,Stay,Intimate,Gender,inter_dom,Religion,Academic])\n",
        "X = np.array(pd.DataFrame(newData))\n",
        "# X = X.reshape(-1,X.shape[0])\n",
        "Y = np.array([DataFrame[\"ToDep\"]])\n",
        "# Y = np.array([DataFrame[\"Dep\"].replace(\"Yes\",1).replace(\"No\",0).replace(math.nan,-1)])"
      ],
      "metadata": {
        "id": "RqdUinWtz6GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BFhsjAvF-qJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsQgM6909Eo4",
        "outputId": "031c4566-0889-4724-b83c-bcce7f5ac3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3., 4., 4., 2., 1., 3., 3., 1., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgGHmNks9Twz",
        "outputId": "ff0d5903-bebd-485b-a6e7-63fc6bb035e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No',\n",
              "        'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
              "        'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No',\n",
              "        'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes',\n",
              "        'No', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes',\n",
              "        'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No',\n",
              "        'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes',\n",
              "        'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes',\n",
              "        'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes',\n",
              "        'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes',\n",
              "        'No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No',\n",
              "        'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
              "        'Yes', 'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No',\n",
              "        'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes',\n",
              "        'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
              "        'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes',\n",
              "        'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No',\n",
              "        'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No',\n",
              "        'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
              "        'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes',\n",
              "        'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No',\n",
              "        'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No',\n",
              "        'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes',\n",
              "        'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No',\n",
              "        'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
              "        'Yes', 'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No',\n",
              "        'Yes', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', nan,\n",
              "        '96', '172', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
              "        nan, nan, nan, nan, nan]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = X[:-18]"
      ],
      "metadata": {
        "id": "YrLvwkbA9jUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y2 = Y[:,:-18]"
      ],
      "metadata": {
        "id": "WtaAsXcl9oFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y2 = Y2.reshape(-1,1)"
      ],
      "metadata": {
        "id": "3u5EVn1n9qZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO4YnDXj-AAm",
        "outputId": "7ba8b46a-8f19-4090-ff45-c583f42006cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  2.,  2.,  3.,  3.,  6.,  3.,  9.,  7.,  3.,  5.,  8.,  1.,\n",
              "         3.,  9.,  6.,  3.,  3.,  7.,  1.,  4.,  3., 13.,  1.,  8., 10.,\n",
              "        13.,  9.,  6.,  7., 10.,  9.,  9.,  2.,  9., 14.,  4., 14., 13.,\n",
              "        15.,  6.,  4., 10., 12.,  6.,  7., 13.,  2.,  0.,  6., 19.,  9.,\n",
              "        10.,  8.,  5.,  8., 17., 12.,  8.,  7.,  5.,  2.,  8.,  7.,  5.,\n",
              "         9., 11.,  9.,  5., 14.,  9.,  5.,  6.,  4.,  2., 10., 11., 10.,\n",
              "        13.,  6.,  6., 10.,  2.,  0., 13., 13.,  8.,  8.,  2., 13.,  3.,\n",
              "         4.,  1.,  6., 17., 21., 14.,  4., 12., 10.,  3.,  6.,  9.,  9.,\n",
              "         7., 25., 19., 11.,  8., 10.,  5., 10.,  2.,  9.,  3., 17.,  6.,\n",
              "         5.,  0.,  6., 14.,  9.,  9.,  3.,  6.,  0.,  8., 10.,  8.,  3.,\n",
              "        13.,  1., 13., 11., 14., 14.,  7., 11., 11., 17.,  6.,  9., 10.,\n",
              "         4., 12.,  0.,  8.,  8., 13.,  5., 10.,  0.,  9.,  5.,  4.,  0.,\n",
              "         8.,  7., 11., 10.,  7., 11.,  4.,  7.,  9.,  1., 11., 13.,  0.,\n",
              "        11.,  6.,  7.,  7.,  9., 24.,  6., 11.,  7.,  3.,  4.,  8., 22.,\n",
              "        12., 15.,  5., 22.,  6., 13., 11.,  9., 10.,  4., 12., 16.,  3.,\n",
              "        17.,  6.,  7., 16.,  8.,  2., 12.,  9.,  7.,  3., 10.,  6.,  6.,\n",
              "         0., 13.,  9.,  7., 20., 21., 23.,  2., 13.,  7., 11.,  5.,  1.,\n",
              "         8.,  8., 11., 11.,  0.,  8., 16.,  7.,  2., 14.,  9., 10., 15.,\n",
              "        10., 12., 11., 11., 10.,  3.,  4., 18.,  9.,  5.,  2.,  7., 10.,\n",
              "         7.,  6.,  9.,  2., 13., 10.,  9.,  6.,  0., 13.,  9.,  9., 17.,\n",
              "        13.,  0., 11.,  8.,  2.,  9.,  1.,  7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches"
      ],
      "metadata": {
        "id": "Y8vs2Xn_8lyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input(9),\n",
        "  tf.keras.layers.Dense(20, activation='relu'),\n",
        "  tf.keras.layers.Dense(30, activation='relu'),\n",
        "  tf.keras.layers.Dense(20, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='relu'),\n",
        "  tf.keras.layers.Dense(5, activation='relu'),\n",
        "  tf.keras.layers.Dense(2, activation='relu'),\n",
        "  tf.keras.layers.Dense(1),\n",
        "])\n",
        "model.summary()\n",
        "# print(model.output_shape)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "          # loss='binary_cross_entropy ',metrics=[\"accuracy\"])\n",
        "          loss='mean_squared_error')#spacekaahzangkunshouhzikkas\n",
        "#wangjile relu xjiu yachi unjiabusuankunxueya hlon ap tt zuo sigmoid caixiangqilaixueyahengaokoukekun shoulachaojikun unbuzaihuwoyouqidtashiqingkunshouyuenxin zhegenan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahcONXKK8nWl",
        "outputId": "f4ddb798-33bf-42d8-c5a4-ad6302984623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_105 (Dense)           (None, 20)                200       \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 30)                630       \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 20)                620       \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 10)                210       \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 2)                 12        \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,730\n",
            "Trainable params: 1,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X2,Y2,epochs=1000,validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jy5yukk8wGW",
        "outputId": "3e827140-cbbb-412d-faee-0959b185b5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "8/8 [==============================] - 1s 24ms/step - loss: 93.3994 - val_loss: 82.0122\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 90.5718 - val_loss: 80.7864\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 89.2852 - val_loss: 79.5781\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 88.0386 - val_loss: 78.3776\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 86.7833 - val_loss: 77.2126\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 85.5733 - val_loss: 76.0549\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 84.3555 - val_loss: 74.9167\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 83.1554 - val_loss: 73.7990\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 81.9934 - val_loss: 72.6838\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 80.8345 - val_loss: 71.5822\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 79.6623 - val_loss: 70.5207\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 78.5481 - val_loss: 69.4579\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 77.4562 - val_loss: 68.4043\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 76.3523 - val_loss: 67.3863\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 75.2812 - val_loss: 66.3911\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 74.2383 - val_loss: 65.4033\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 73.2019 - val_loss: 64.4248\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 72.1685 - val_loss: 63.4727\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 71.1883 - val_loss: 62.5247\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 70.1715 - val_loss: 61.6162\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 69.2215 - val_loss: 60.7088\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 68.2637 - val_loss: 59.8086\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 67.3176 - val_loss: 58.9282\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 66.3772 - val_loss: 58.0683\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 65.4734 - val_loss: 57.2030\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 64.5664 - val_loss: 56.3657\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 63.6858 - val_loss: 55.5439\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 62.8194 - val_loss: 54.7420\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 61.9805 - val_loss: 53.9488\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 61.1157 - val_loss: 53.1837\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 60.3235 - val_loss: 52.4093\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 59.5006 - val_loss: 51.6627\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 58.7192 - val_loss: 50.9219\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 57.9300 - val_loss: 50.2017\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 57.1684 - val_loss: 49.4994\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 56.4219 - val_loss: 48.8077\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 55.7003 - val_loss: 48.1209\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 54.9647 - val_loss: 47.4620\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 54.2540 - val_loss: 46.8208\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 53.5728 - val_loss: 46.1793\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 52.8762 - val_loss: 45.5534\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 52.2184 - val_loss: 44.9223\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 51.5377 - val_loss: 44.3237\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 50.8991 - val_loss: 43.7291\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 50.2567 - val_loss: 43.1558\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 49.6434 - val_loss: 42.5836\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 49.0358 - val_loss: 42.0233\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 48.4484 - val_loss: 41.4685\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 47.8414 - val_loss: 40.9334\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 47.2686 - val_loss: 40.4064\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 46.7063 - val_loss: 39.8940\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 46.1524 - val_loss: 39.3918\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 45.6022 - val_loss: 38.9040\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 45.0765 - val_loss: 38.4202\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 44.5605 - val_loss: 37.9497\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 44.0473 - val_loss: 37.4926\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 43.5570 - val_loss: 37.0395\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 43.0584 - val_loss: 36.6046\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 42.5797 - val_loss: 36.1769\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 42.1183 - val_loss: 35.7524\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 41.6458 - val_loss: 35.3460\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 41.2158 - val_loss: 34.9374\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 40.7713 - val_loss: 34.5455\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 40.3438 - val_loss: 34.1616\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 39.9192 - val_loss: 33.7879\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 39.4997 - val_loss: 33.4276\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 39.1030 - val_loss: 33.0682\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 38.7204 - val_loss: 32.7081\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 38.3232 - val_loss: 32.3700\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 37.9597 - val_loss: 32.0361\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 37.5835 - val_loss: 31.7180\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 37.2236 - val_loss: 31.4050\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 36.8923 - val_loss: 31.0870\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 36.5228 - val_loss: 30.7956\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 36.2068 - val_loss: 30.4948\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 35.8767 - val_loss: 30.2051\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 35.5510 - val_loss: 29.9283\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 35.2406 - val_loss: 29.6493\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 34.9357 - val_loss: 29.3760\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 34.6286 - val_loss: 29.1157\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 34.3427 - val_loss: 28.8571\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 34.0456 - val_loss: 28.6177\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 33.7714 - val_loss: 28.3829\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 33.5116 - val_loss: 28.1476\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 33.2422 - val_loss: 27.9193\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 32.9767 - val_loss: 27.7022\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 32.7244 - val_loss: 27.4891\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 32.4920 - val_loss: 27.2726\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 32.2512 - val_loss: 27.0677\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 32.0153 - val_loss: 26.8745\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 31.7860 - val_loss: 26.6893\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 31.5758 - val_loss: 26.5015\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 31.3605 - val_loss: 26.3200\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 31.1455 - val_loss: 26.1460\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 30.9549 - val_loss: 25.9734\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 30.7467 - val_loss: 25.8121\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 30.5495 - val_loss: 25.6583\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 30.3709 - val_loss: 25.5017\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 30.1888 - val_loss: 25.3476\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 30.0027 - val_loss: 25.2045\n",
            "Epoch 101/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 29.8357 - val_loss: 25.0622\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 29.6609 - val_loss: 24.9254\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 29.5112 - val_loss: 24.7832\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 29.3398 - val_loss: 24.6579\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 29.1870 - val_loss: 24.5385\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 29.0431 - val_loss: 24.4157\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 28.9034 - val_loss: 24.2959\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 28.7583 - val_loss: 24.1852\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 28.6189 - val_loss: 24.0783\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 28.4828 - val_loss: 23.9754\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 28.3543 - val_loss: 23.8735\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 28.2322 - val_loss: 23.7677\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 28.1113 - val_loss: 23.6666\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 27.9822 - val_loss: 23.5775\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 27.8714 - val_loss: 23.4931\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 27.7685 - val_loss: 23.4062\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 27.6534 - val_loss: 23.3285\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 27.5514 - val_loss: 23.2521\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 27.4577 - val_loss: 23.1734\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 27.3540 - val_loss: 23.1011\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 27.2591 - val_loss: 23.0294\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 27.1703 - val_loss: 22.9580\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 27.0777 - val_loss: 22.8916\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 26.9906 - val_loss: 22.8276\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 26.9137 - val_loss: 22.7630\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 26.8230 - val_loss: 22.7054\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 26.7446 - val_loss: 22.6469\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 26.6726 - val_loss: 22.5902\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 26.5927 - val_loss: 22.5417\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 26.5324 - val_loss: 22.4922\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 26.4608 - val_loss: 22.4475\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 26.3962 - val_loss: 22.4058\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 26.3373 - val_loss: 22.3637\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 26.2744 - val_loss: 22.3233\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 26.2190 - val_loss: 22.2806\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 26.1554 - val_loss: 22.2394\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 26.0997 - val_loss: 22.2011\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 26.0482 - val_loss: 22.1647\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 25.9980 - val_loss: 22.1305\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.9458 - val_loss: 22.1003\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.8970 - val_loss: 22.0703\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.8519 - val_loss: 22.0422\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.8046 - val_loss: 22.0183\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.7684 - val_loss: 21.9895\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.7307 - val_loss: 21.9619\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 25.6845 - val_loss: 21.9391\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.6479 - val_loss: 21.9173\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.6092 - val_loss: 21.8969\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.5759 - val_loss: 21.8758\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.5414 - val_loss: 21.8555\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.5105 - val_loss: 21.8358\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.4765 - val_loss: 21.8180\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.4405 - val_loss: 21.8018\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.4114 - val_loss: 21.7855\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.3810 - val_loss: 21.7709\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.3525 - val_loss: 21.7563\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.3260 - val_loss: 21.7419\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.3000 - val_loss: 21.7297\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 25.2750 - val_loss: 21.7194\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.2509 - val_loss: 21.7097\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 25.2355 - val_loss: 21.6982\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.2114 - val_loss: 21.6892\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.1883 - val_loss: 21.6823\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.1769 - val_loss: 21.6738\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.1516 - val_loss: 21.6675\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.1373 - val_loss: 21.6602\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.1172 - val_loss: 21.6546\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.1041 - val_loss: 21.6475\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 25.0857 - val_loss: 21.6423\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.0699 - val_loss: 21.6375\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.0542 - val_loss: 21.6333\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.0420 - val_loss: 21.6290\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.0277 - val_loss: 21.6255\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.0151 - val_loss: 21.6226\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 25.0037 - val_loss: 21.6198\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.9918 - val_loss: 21.6177\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.9815 - val_loss: 21.6157\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.9732 - val_loss: 21.6136\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.9600 - val_loss: 21.6121\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.9528 - val_loss: 21.6107\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.9414 - val_loss: 21.6097\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.9332 - val_loss: 21.6088\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.9243 - val_loss: 21.6083\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.9170 - val_loss: 21.6079\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.9103 - val_loss: 21.6077\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.9010 - val_loss: 21.6077\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.8935 - val_loss: 21.6079\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8868 - val_loss: 21.6083\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8814 - val_loss: 21.6091\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8725 - val_loss: 21.6098\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8664 - val_loss: 21.6106\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8634 - val_loss: 21.6120\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.8552 - val_loss: 21.6133\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8529 - val_loss: 21.6150\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8448 - val_loss: 21.6159\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8441 - val_loss: 21.6175\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8384 - val_loss: 21.6177\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8354 - val_loss: 21.6189\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8334 - val_loss: 21.6209\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8280 - val_loss: 21.6220\n",
            "Epoch 201/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8257 - val_loss: 21.6240\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8217 - val_loss: 21.6256\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8184 - val_loss: 21.6278\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8143 - val_loss: 21.6296\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.8119 - val_loss: 21.6319\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.8101 - val_loss: 21.6342\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.8057 - val_loss: 21.6357\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.8041 - val_loss: 21.6382\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.8029 - val_loss: 21.6409\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7996 - val_loss: 21.6421\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7986 - val_loss: 21.6441\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7958 - val_loss: 21.6458\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7942 - val_loss: 21.6476\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7934 - val_loss: 21.6496\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7910 - val_loss: 21.6502\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7919 - val_loss: 21.6529\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7886 - val_loss: 21.6533\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7909 - val_loss: 21.6566\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7860 - val_loss: 21.6587\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7845 - val_loss: 21.6600\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7839 - val_loss: 21.6610\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7836 - val_loss: 21.6631\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7825 - val_loss: 21.6653\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7820 - val_loss: 21.6672\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7803 - val_loss: 21.6668\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7803 - val_loss: 21.6691\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7789 - val_loss: 21.6701\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7781 - val_loss: 21.6709\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7777 - val_loss: 21.6722\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7773 - val_loss: 21.6744\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7760 - val_loss: 21.6765\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7761 - val_loss: 21.6791\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7749 - val_loss: 21.6808\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7737 - val_loss: 21.6829\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7730 - val_loss: 21.6837\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7738 - val_loss: 21.6887\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7706 - val_loss: 21.6899\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7705 - val_loss: 21.6929\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7698 - val_loss: 21.6947\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7691 - val_loss: 21.6957\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7692 - val_loss: 21.6966\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7686 - val_loss: 21.6986\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7687 - val_loss: 21.7010\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7676 - val_loss: 21.7026\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7671 - val_loss: 21.7041\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7674 - val_loss: 21.7067\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7664 - val_loss: 21.7073\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7668 - val_loss: 21.7090\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7665 - val_loss: 21.7089\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7664 - val_loss: 21.7094\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7664 - val_loss: 21.7130\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7659 - val_loss: 21.7154\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7654 - val_loss: 21.7173\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7660 - val_loss: 21.7201\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7658 - val_loss: 21.7204\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7646 - val_loss: 21.7213\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7659 - val_loss: 21.7229\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7646 - val_loss: 21.7224\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7643 - val_loss: 21.7209\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7664 - val_loss: 21.7186\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7668 - val_loss: 21.7221\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7672 - val_loss: 21.7193\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7211\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7665 - val_loss: 21.7244\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7646 - val_loss: 21.7235\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7263\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7269\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7641 - val_loss: 21.7269\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7637 - val_loss: 21.7298\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7637 - val_loss: 21.7311\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7640 - val_loss: 21.7325\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7637 - val_loss: 21.7351\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7636 - val_loss: 21.7361\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7637 - val_loss: 21.7368\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7345\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7345\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7629 - val_loss: 21.7381\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7654 - val_loss: 21.7434\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7635 - val_loss: 21.7435\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7648 - val_loss: 21.7408\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7635 - val_loss: 21.7400\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7642 - val_loss: 21.7370\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7641 - val_loss: 21.7387\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7395\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7642 - val_loss: 21.7375\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 24.7634 - val_loss: 21.7407\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7632 - val_loss: 21.7432\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7633 - val_loss: 21.7456\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7636 - val_loss: 21.7471\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7462\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7630 - val_loss: 21.7482\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7633 - val_loss: 21.7483\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7632 - val_loss: 21.7505\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7634 - val_loss: 21.7530\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7634 - val_loss: 21.7530\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7529\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7543\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7529\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7644 - val_loss: 21.7545\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7502\n",
            "Epoch 301/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7517\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7650 - val_loss: 21.7543\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7653 - val_loss: 21.7493\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7633 - val_loss: 21.7494\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7633 - val_loss: 21.7483\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7631 - val_loss: 21.7473\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7448\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7641 - val_loss: 21.7472\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7661 - val_loss: 21.7494\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7628 - val_loss: 21.7469\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7631 - val_loss: 21.7448\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7636 - val_loss: 21.7439\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7638 - val_loss: 21.7396\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7636 - val_loss: 21.7377\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7388\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7390\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7664 - val_loss: 21.7415\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7645 - val_loss: 21.7383\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7661 - val_loss: 21.7429\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7645 - val_loss: 21.7432\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7650 - val_loss: 21.7432\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7649 - val_loss: 21.7380\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7641 - val_loss: 21.7366\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7639 - val_loss: 21.7389\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7635 - val_loss: 21.7391\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7649 - val_loss: 21.7395\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7654 - val_loss: 21.7367\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7407\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7633 - val_loss: 21.7415\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7633 - val_loss: 21.7419\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7644 - val_loss: 21.7443\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7639 - val_loss: 21.7407\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7645 - val_loss: 21.7407\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7636 - val_loss: 21.7410\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7634 - val_loss: 21.7413\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7637 - val_loss: 21.7409\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7631 - val_loss: 21.7385\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7634 - val_loss: 21.7366\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7645 - val_loss: 21.7328\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7314\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7642 - val_loss: 21.7316\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7642 - val_loss: 21.7371\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7647 - val_loss: 21.7401\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7633 - val_loss: 21.7397\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7647 - val_loss: 21.7376\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7371\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7634 - val_loss: 21.7386\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7644 - val_loss: 21.7415\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7646 - val_loss: 21.7423\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7635 - val_loss: 21.7374\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7344\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7650 - val_loss: 21.7319\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7640 - val_loss: 21.7317\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7637 - val_loss: 21.7324\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7640 - val_loss: 21.7358\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7645 - val_loss: 21.7359\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7638 - val_loss: 21.7378\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7637 - val_loss: 21.7393\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7662 - val_loss: 21.7370\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 24.7629 - val_loss: 21.7419\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7644 - val_loss: 21.7411\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7667 - val_loss: 21.7475\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7634 - val_loss: 21.7480\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7661 - val_loss: 21.7527\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7632 - val_loss: 21.7518\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7646 - val_loss: 21.7497\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7634 - val_loss: 21.7500\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7639 - val_loss: 21.7507\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7653 - val_loss: 21.7495\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7524\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7638 - val_loss: 21.7510\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7504\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7632 - val_loss: 21.7496\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7647 - val_loss: 21.7475\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7636 - val_loss: 21.7476\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7631 - val_loss: 21.7478\n",
            "Epoch 377/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7662 - val_loss: 21.7513\n",
            "Epoch 378/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7641 - val_loss: 21.7532\n",
            "Epoch 379/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7638 - val_loss: 21.7491\n",
            "Epoch 380/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7645 - val_loss: 21.7461\n",
            "Epoch 381/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7642 - val_loss: 21.7442\n",
            "Epoch 382/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7644 - val_loss: 21.7487\n",
            "Epoch 383/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7480\n",
            "Epoch 384/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7634 - val_loss: 21.7469\n",
            "Epoch 385/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7633 - val_loss: 21.7455\n",
            "Epoch 386/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7631 - val_loss: 21.7440\n",
            "Epoch 387/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7639 - val_loss: 21.7423\n",
            "Epoch 388/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7653 - val_loss: 21.7440\n",
            "Epoch 389/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7404\n",
            "Epoch 390/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7644 - val_loss: 21.7420\n",
            "Epoch 391/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7639 - val_loss: 21.7410\n",
            "Epoch 392/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7381\n",
            "Epoch 393/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7637 - val_loss: 21.7380\n",
            "Epoch 394/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7640 - val_loss: 21.7411\n",
            "Epoch 395/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7415\n",
            "Epoch 396/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7649 - val_loss: 21.7479\n",
            "Epoch 397/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7634 - val_loss: 21.7470\n",
            "Epoch 398/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7640 - val_loss: 21.7489\n",
            "Epoch 399/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7664 - val_loss: 21.7461\n",
            "Epoch 400/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7655 - val_loss: 21.7499\n",
            "Epoch 401/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7647 - val_loss: 21.7551\n",
            "Epoch 402/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7641 - val_loss: 21.7531\n",
            "Epoch 403/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7541\n",
            "Epoch 404/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7685 - val_loss: 21.7480\n",
            "Epoch 405/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7641 - val_loss: 21.7482\n",
            "Epoch 406/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7636 - val_loss: 21.7532\n",
            "Epoch 407/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7648 - val_loss: 21.7575\n",
            "Epoch 408/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7641 - val_loss: 21.7566\n",
            "Epoch 409/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7648 - val_loss: 21.7606\n",
            "Epoch 410/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7640 - val_loss: 21.7603\n",
            "Epoch 411/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7644 - val_loss: 21.7530\n",
            "Epoch 412/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7644 - val_loss: 21.7514\n",
            "Epoch 413/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7507\n",
            "Epoch 414/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7637 - val_loss: 21.7510\n",
            "Epoch 415/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7641 - val_loss: 21.7494\n",
            "Epoch 416/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7647 - val_loss: 21.7508\n",
            "Epoch 417/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7636 - val_loss: 21.7490\n",
            "Epoch 418/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7486\n",
            "Epoch 419/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7685 - val_loss: 21.7422\n",
            "Epoch 420/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7438\n",
            "Epoch 421/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7636 - val_loss: 21.7439\n",
            "Epoch 422/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7632 - val_loss: 21.7444\n",
            "Epoch 423/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7640 - val_loss: 21.7473\n",
            "Epoch 424/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7632 - val_loss: 21.7517\n",
            "Epoch 425/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7641 - val_loss: 21.7560\n",
            "Epoch 426/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7644 - val_loss: 21.7548\n",
            "Epoch 427/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7671 - val_loss: 21.7588\n",
            "Epoch 428/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7643 - val_loss: 21.7512\n",
            "Epoch 429/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7631 - val_loss: 21.7480\n",
            "Epoch 430/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7646 - val_loss: 21.7496\n",
            "Epoch 431/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7628 - val_loss: 21.7456\n",
            "Epoch 432/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7639 - val_loss: 21.7462\n",
            "Epoch 433/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7633 - val_loss: 21.7453\n",
            "Epoch 434/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7634 - val_loss: 21.7460\n",
            "Epoch 435/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7663 - val_loss: 21.7519\n",
            "Epoch 436/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7645 - val_loss: 21.7518\n",
            "Epoch 437/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7627 - val_loss: 21.7487\n",
            "Epoch 438/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7631 - val_loss: 21.7469\n",
            "Epoch 439/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7634 - val_loss: 21.7448\n",
            "Epoch 440/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7641 - val_loss: 21.7453\n",
            "Epoch 441/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7633 - val_loss: 21.7455\n",
            "Epoch 442/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7465\n",
            "Epoch 443/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7640 - val_loss: 21.7455\n",
            "Epoch 444/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7387\n",
            "Epoch 445/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7390\n",
            "Epoch 446/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7762 - val_loss: 21.7300\n",
            "Epoch 447/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7372\n",
            "Epoch 448/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7640 - val_loss: 21.7384\n",
            "Epoch 449/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7637 - val_loss: 21.7375\n",
            "Epoch 450/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7639 - val_loss: 21.7335\n",
            "Epoch 451/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7657 - val_loss: 21.7315\n",
            "Epoch 452/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7639 - val_loss: 21.7344\n",
            "Epoch 453/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7643 - val_loss: 21.7333\n",
            "Epoch 454/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7646 - val_loss: 21.7341\n",
            "Epoch 455/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7660 - val_loss: 21.7383\n",
            "Epoch 456/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7350\n",
            "Epoch 457/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7641 - val_loss: 21.7352\n",
            "Epoch 458/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7638 - val_loss: 21.7351\n",
            "Epoch 459/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7649 - val_loss: 21.7318\n",
            "Epoch 460/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7657 - val_loss: 21.7299\n",
            "Epoch 461/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7696 - val_loss: 21.7272\n",
            "Epoch 462/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7342\n",
            "Epoch 463/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7653 - val_loss: 21.7329\n",
            "Epoch 464/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7639 - val_loss: 21.7371\n",
            "Epoch 465/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7663 - val_loss: 21.7343\n",
            "Epoch 466/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7665 - val_loss: 21.7394\n",
            "Epoch 467/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7643 - val_loss: 21.7381\n",
            "Epoch 468/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7657 - val_loss: 21.7288\n",
            "Epoch 469/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7645 - val_loss: 21.7245\n",
            "Epoch 470/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7647 - val_loss: 21.7237\n",
            "Epoch 471/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7646 - val_loss: 21.7244\n",
            "Epoch 472/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7673 - val_loss: 21.7280\n",
            "Epoch 473/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7649 - val_loss: 21.7258\n",
            "Epoch 474/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7656 - val_loss: 21.7312\n",
            "Epoch 475/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7642 - val_loss: 21.7336\n",
            "Epoch 476/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7640 - val_loss: 21.7326\n",
            "Epoch 477/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7663 - val_loss: 21.7359\n",
            "Epoch 478/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7665 - val_loss: 21.7306\n",
            "Epoch 479/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7657 - val_loss: 21.7359\n",
            "Epoch 480/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7336\n",
            "Epoch 481/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7646 - val_loss: 21.7315\n",
            "Epoch 482/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7643 - val_loss: 21.7333\n",
            "Epoch 483/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7390\n",
            "Epoch 484/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7639 - val_loss: 21.7429\n",
            "Epoch 485/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7641 - val_loss: 21.7420\n",
            "Epoch 486/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7466\n",
            "Epoch 487/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7635 - val_loss: 21.7461\n",
            "Epoch 488/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7640 - val_loss: 21.7455\n",
            "Epoch 489/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7459\n",
            "Epoch 490/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7643 - val_loss: 21.7454\n",
            "Epoch 491/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7659 - val_loss: 21.7545\n",
            "Epoch 492/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7649 - val_loss: 21.7584\n",
            "Epoch 493/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7683 - val_loss: 21.7619\n",
            "Epoch 494/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7606\n",
            "Epoch 495/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7652 - val_loss: 21.7533\n",
            "Epoch 496/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7657 - val_loss: 21.7517\n",
            "Epoch 497/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7518\n",
            "Epoch 498/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7644 - val_loss: 21.7499\n",
            "Epoch 499/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7640 - val_loss: 21.7509\n",
            "Epoch 500/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7483\n",
            "Epoch 501/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7635 - val_loss: 21.7481\n",
            "Epoch 502/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7666 - val_loss: 21.7453\n",
            "Epoch 503/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7646 - val_loss: 21.7515\n",
            "Epoch 504/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7646 - val_loss: 21.7531\n",
            "Epoch 505/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7646 - val_loss: 21.7488\n",
            "Epoch 506/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7466\n",
            "Epoch 507/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7468\n",
            "Epoch 508/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 24.7637 - val_loss: 21.7457\n",
            "Epoch 509/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7458\n",
            "Epoch 510/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7639 - val_loss: 21.7484\n",
            "Epoch 511/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7647 - val_loss: 21.7498\n",
            "Epoch 512/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7633 - val_loss: 21.7480\n",
            "Epoch 513/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7640 - val_loss: 21.7443\n",
            "Epoch 514/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7662 - val_loss: 21.7400\n",
            "Epoch 515/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7633 - val_loss: 21.7439\n",
            "Epoch 516/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7649 - val_loss: 21.7423\n",
            "Epoch 517/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7633 - val_loss: 21.7449\n",
            "Epoch 518/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7673 - val_loss: 21.7436\n",
            "Epoch 519/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7640 - val_loss: 21.7538\n",
            "Epoch 520/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7641 - val_loss: 21.7575\n",
            "Epoch 521/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7671 - val_loss: 21.7514\n",
            "Epoch 522/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7674 - val_loss: 21.7557\n",
            "Epoch 523/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7636 - val_loss: 21.7513\n",
            "Epoch 524/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7674 - val_loss: 21.7427\n",
            "Epoch 525/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7669 - val_loss: 21.7387\n",
            "Epoch 526/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7652 - val_loss: 21.7446\n",
            "Epoch 527/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7471\n",
            "Epoch 528/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7486\n",
            "Epoch 529/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7651 - val_loss: 21.7511\n",
            "Epoch 530/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7653 - val_loss: 21.7461\n",
            "Epoch 531/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7435\n",
            "Epoch 532/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7741 - val_loss: 21.7333\n",
            "Epoch 533/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7646 - val_loss: 21.7336\n",
            "Epoch 534/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7636 - val_loss: 21.7355\n",
            "Epoch 535/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7641 - val_loss: 21.7373\n",
            "Epoch 536/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7656 - val_loss: 21.7350\n",
            "Epoch 537/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7647 - val_loss: 21.7387\n",
            "Epoch 538/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7636 - val_loss: 21.7412\n",
            "Epoch 539/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7421\n",
            "Epoch 540/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7637 - val_loss: 21.7449\n",
            "Epoch 541/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7659 - val_loss: 21.7499\n",
            "Epoch 542/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7503\n",
            "Epoch 543/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7688 - val_loss: 21.7410\n",
            "Epoch 544/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7654 - val_loss: 21.7462\n",
            "Epoch 545/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7645 - val_loss: 21.7453\n",
            "Epoch 546/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7637 - val_loss: 21.7459\n",
            "Epoch 547/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7633 - val_loss: 21.7455\n",
            "Epoch 548/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7655 - val_loss: 21.7468\n",
            "Epoch 549/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7631 - val_loss: 21.7435\n",
            "Epoch 550/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7665 - val_loss: 21.7361\n",
            "Epoch 551/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7645 - val_loss: 21.7321\n",
            "Epoch 552/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7655 - val_loss: 21.7337\n",
            "Epoch 553/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7661 - val_loss: 21.7364\n",
            "Epoch 554/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7646 - val_loss: 21.7353\n",
            "Epoch 555/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7692 - val_loss: 21.7305\n",
            "Epoch 556/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7758 - val_loss: 21.7449\n",
            "Epoch 557/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7661 - val_loss: 21.7444\n",
            "Epoch 558/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7649 - val_loss: 21.7414\n",
            "Epoch 559/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7402\n",
            "Epoch 560/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7642 - val_loss: 21.7430\n",
            "Epoch 561/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7660 - val_loss: 21.7402\n",
            "Epoch 562/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7406\n",
            "Epoch 563/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7392\n",
            "Epoch 564/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7641 - val_loss: 21.7362\n",
            "Epoch 565/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7660 - val_loss: 21.7419\n",
            "Epoch 566/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7657 - val_loss: 21.7386\n",
            "Epoch 567/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7644 - val_loss: 21.7360\n",
            "Epoch 568/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 24.7639 - val_loss: 21.7369\n",
            "Epoch 569/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7639 - val_loss: 21.7352\n",
            "Epoch 570/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7643 - val_loss: 21.7363\n",
            "Epoch 571/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7666 - val_loss: 21.7437\n",
            "Epoch 572/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7635 - val_loss: 21.7423\n",
            "Epoch 573/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7682 - val_loss: 21.7457\n",
            "Epoch 574/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7647 - val_loss: 21.7416\n",
            "Epoch 575/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7707 - val_loss: 21.7311\n",
            "Epoch 576/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7344\n",
            "Epoch 577/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7643 - val_loss: 21.7364\n",
            "Epoch 578/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7633 - val_loss: 21.7340\n",
            "Epoch 579/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7650 - val_loss: 21.7288\n",
            "Epoch 580/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7648 - val_loss: 21.7285\n",
            "Epoch 581/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7655 - val_loss: 21.7318\n",
            "Epoch 582/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7649 - val_loss: 21.7281\n",
            "Epoch 583/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7707 - val_loss: 21.7352\n",
            "Epoch 584/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7657 - val_loss: 21.7320\n",
            "Epoch 585/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7645 - val_loss: 21.7352\n",
            "Epoch 586/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7641 - val_loss: 21.7361\n",
            "Epoch 587/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7637 - val_loss: 21.7352\n",
            "Epoch 588/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7634 - val_loss: 21.7353\n",
            "Epoch 589/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7664 - val_loss: 21.7338\n",
            "Epoch 590/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7693 - val_loss: 21.7438\n",
            "Epoch 591/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7677 - val_loss: 21.7382\n",
            "Epoch 592/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7649 - val_loss: 21.7431\n",
            "Epoch 593/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7657 - val_loss: 21.7477\n",
            "Epoch 594/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7424\n",
            "Epoch 595/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7730 - val_loss: 21.7497\n",
            "Epoch 596/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7655 - val_loss: 21.7397\n",
            "Epoch 597/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7376\n",
            "Epoch 598/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7645 - val_loss: 21.7382\n",
            "Epoch 599/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7639 - val_loss: 21.7400\n",
            "Epoch 600/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7639 - val_loss: 21.7397\n",
            "Epoch 601/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7669 - val_loss: 21.7431\n",
            "Epoch 602/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7432\n",
            "Epoch 603/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7663 - val_loss: 21.7372\n",
            "Epoch 604/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7633 - val_loss: 21.7409\n",
            "Epoch 605/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7465\n",
            "Epoch 606/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7639 - val_loss: 21.7442\n",
            "Epoch 607/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7648 - val_loss: 21.7419\n",
            "Epoch 608/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7648 - val_loss: 21.7382\n",
            "Epoch 609/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7416\n",
            "Epoch 610/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7653 - val_loss: 21.7449\n",
            "Epoch 611/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7662 - val_loss: 21.7414\n",
            "Epoch 612/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7636 - val_loss: 21.7418\n",
            "Epoch 613/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7652 - val_loss: 21.7397\n",
            "Epoch 614/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7752 - val_loss: 21.7311\n",
            "Epoch 615/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7670 - val_loss: 21.7433\n",
            "Epoch 616/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7455\n",
            "Epoch 617/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7652 - val_loss: 21.7393\n",
            "Epoch 618/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7656 - val_loss: 21.7453\n",
            "Epoch 619/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7663 - val_loss: 21.7447\n",
            "Epoch 620/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7637 - val_loss: 21.7498\n",
            "Epoch 621/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7491\n",
            "Epoch 622/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 24.7659 - val_loss: 21.7552\n",
            "Epoch 623/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7642 - val_loss: 21.7576\n",
            "Epoch 624/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7656 - val_loss: 21.7586\n",
            "Epoch 625/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7644 - val_loss: 21.7497\n",
            "Epoch 626/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7630 - val_loss: 21.7474\n",
            "Epoch 627/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7446\n",
            "Epoch 628/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7482\n",
            "Epoch 629/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7648 - val_loss: 21.7511\n",
            "Epoch 630/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7642 - val_loss: 21.7527\n",
            "Epoch 631/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7656 - val_loss: 21.7518\n",
            "Epoch 632/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7638 - val_loss: 21.7597\n",
            "Epoch 633/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7647 - val_loss: 21.7644\n",
            "Epoch 634/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7652 - val_loss: 21.7663\n",
            "Epoch 635/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7752 - val_loss: 21.7531\n",
            "Epoch 636/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7645 - val_loss: 21.7525\n",
            "Epoch 637/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7565\n",
            "Epoch 638/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7553\n",
            "Epoch 639/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7667 - val_loss: 21.7589\n",
            "Epoch 640/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7630 - val_loss: 21.7555\n",
            "Epoch 641/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7635 - val_loss: 21.7529\n",
            "Epoch 642/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7639 - val_loss: 21.7507\n",
            "Epoch 643/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7496\n",
            "Epoch 644/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7520\n",
            "Epoch 645/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7678 - val_loss: 21.7561\n",
            "Epoch 646/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7636 - val_loss: 21.7481\n",
            "Epoch 647/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7430\n",
            "Epoch 648/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7633 - val_loss: 21.7409\n",
            "Epoch 649/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7387\n",
            "Epoch 650/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7645 - val_loss: 21.7357\n",
            "Epoch 651/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7690 - val_loss: 21.7299\n",
            "Epoch 652/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7647 - val_loss: 21.7388\n",
            "Epoch 653/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7636 - val_loss: 21.7412\n",
            "Epoch 654/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7629 - val_loss: 21.7450\n",
            "Epoch 655/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7655 - val_loss: 21.7507\n",
            "Epoch 656/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7646 - val_loss: 21.7483\n",
            "Epoch 657/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7443\n",
            "Epoch 658/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7679 - val_loss: 21.7512\n",
            "Epoch 659/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7647 - val_loss: 21.7465\n",
            "Epoch 660/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7640 - val_loss: 21.7458\n",
            "Epoch 661/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7640 - val_loss: 21.7451\n",
            "Epoch 662/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7648 - val_loss: 21.7469\n",
            "Epoch 663/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7679 - val_loss: 21.7380\n",
            "Epoch 664/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7641 - val_loss: 21.7404\n",
            "Epoch 665/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7645 - val_loss: 21.7380\n",
            "Epoch 666/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7648 - val_loss: 21.7424\n",
            "Epoch 667/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7467\n",
            "Epoch 668/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7447\n",
            "Epoch 669/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7485\n",
            "Epoch 670/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7643 - val_loss: 21.7491\n",
            "Epoch 671/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7655 - val_loss: 21.7447\n",
            "Epoch 672/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7648 - val_loss: 21.7469\n",
            "Epoch 673/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7434\n",
            "Epoch 674/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7655 - val_loss: 21.7457\n",
            "Epoch 675/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7669 - val_loss: 21.7368\n",
            "Epoch 676/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7662 - val_loss: 21.7404\n",
            "Epoch 677/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7648 - val_loss: 21.7392\n",
            "Epoch 678/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7644 - val_loss: 21.7368\n",
            "Epoch 679/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7649 - val_loss: 21.7356\n",
            "Epoch 680/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7649 - val_loss: 21.7396\n",
            "Epoch 681/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7658 - val_loss: 21.7351\n",
            "Epoch 682/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7633 - val_loss: 21.7380\n",
            "Epoch 683/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7661 - val_loss: 21.7366\n",
            "Epoch 684/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7440\n",
            "Epoch 685/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7696 - val_loss: 21.7508\n",
            "Epoch 686/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7641 - val_loss: 21.7447\n",
            "Epoch 687/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7450\n",
            "Epoch 688/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7645 - val_loss: 21.7410\n",
            "Epoch 689/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7460\n",
            "Epoch 690/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7463\n",
            "Epoch 691/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7639 - val_loss: 21.7427\n",
            "Epoch 692/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7636 - val_loss: 21.7431\n",
            "Epoch 693/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7651 - val_loss: 21.7420\n",
            "Epoch 694/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7639 - val_loss: 21.7497\n",
            "Epoch 695/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7639 - val_loss: 21.7481\n",
            "Epoch 696/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7633 - val_loss: 21.7493\n",
            "Epoch 697/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7655 - val_loss: 21.7544\n",
            "Epoch 698/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7546\n",
            "Epoch 699/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7647 - val_loss: 21.7545\n",
            "Epoch 700/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7656 - val_loss: 21.7562\n",
            "Epoch 701/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7665 - val_loss: 21.7464\n",
            "Epoch 702/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7477\n",
            "Epoch 703/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7492\n",
            "Epoch 704/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7509\n",
            "Epoch 705/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7624 - val_loss: 21.7552\n",
            "Epoch 706/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7674 - val_loss: 21.7637\n",
            "Epoch 707/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7672 - val_loss: 21.7728\n",
            "Epoch 708/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7668 - val_loss: 21.7756\n",
            "Epoch 709/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7664 - val_loss: 21.7668\n",
            "Epoch 710/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7667 - val_loss: 21.7600\n",
            "Epoch 711/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7647 - val_loss: 21.7614\n",
            "Epoch 712/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7572\n",
            "Epoch 713/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7646 - val_loss: 21.7496\n",
            "Epoch 714/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7673 - val_loss: 21.7514\n",
            "Epoch 715/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7703 - val_loss: 21.7464\n",
            "Epoch 716/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7637 - val_loss: 21.7511\n",
            "Epoch 717/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7513\n",
            "Epoch 718/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7645 - val_loss: 21.7484\n",
            "Epoch 719/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7633 - val_loss: 21.7507\n",
            "Epoch 720/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7643 - val_loss: 21.7515\n",
            "Epoch 721/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7541\n",
            "Epoch 722/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7665 - val_loss: 21.7500\n",
            "Epoch 723/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7631 - val_loss: 21.7512\n",
            "Epoch 724/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7523\n",
            "Epoch 725/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7740 - val_loss: 21.7637\n",
            "Epoch 726/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7678 - val_loss: 21.7554\n",
            "Epoch 727/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7662 - val_loss: 21.7563\n",
            "Epoch 728/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7656 - val_loss: 21.7498\n",
            "Epoch 729/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7470\n",
            "Epoch 730/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7663 - val_loss: 21.7377\n",
            "Epoch 731/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7646 - val_loss: 21.7385\n",
            "Epoch 732/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7395\n",
            "Epoch 733/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7652 - val_loss: 21.7355\n",
            "Epoch 734/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7709 - val_loss: 21.7444\n",
            "Epoch 735/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7642 - val_loss: 21.7467\n",
            "Epoch 736/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7662 - val_loss: 21.7453\n",
            "Epoch 737/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7642 - val_loss: 21.7453\n",
            "Epoch 738/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7464\n",
            "Epoch 739/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7640 - val_loss: 21.7505\n",
            "Epoch 740/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7524\n",
            "Epoch 741/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7648 - val_loss: 21.7514\n",
            "Epoch 742/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7640 - val_loss: 21.7532\n",
            "Epoch 743/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7628 - val_loss: 21.7601\n",
            "Epoch 744/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7651 - val_loss: 21.7659\n",
            "Epoch 745/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7666\n",
            "Epoch 746/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7633 - val_loss: 21.7740\n",
            "Epoch 747/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7679 - val_loss: 21.7818\n",
            "Epoch 748/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7659 - val_loss: 21.7775\n",
            "Epoch 749/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7664 - val_loss: 21.7805\n",
            "Epoch 750/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7656 - val_loss: 21.7761\n",
            "Epoch 751/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7677 - val_loss: 21.7808\n",
            "Epoch 752/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7674 - val_loss: 21.7713\n",
            "Epoch 753/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7657 - val_loss: 21.7697\n",
            "Epoch 754/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7649 - val_loss: 21.7681\n",
            "Epoch 755/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7644 - val_loss: 21.7627\n",
            "Epoch 756/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7641 - val_loss: 21.7624\n",
            "Epoch 757/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7645 - val_loss: 21.7597\n",
            "Epoch 758/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7642 - val_loss: 21.7562\n",
            "Epoch 759/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7641 - val_loss: 21.7524\n",
            "Epoch 760/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7638 - val_loss: 21.7523\n",
            "Epoch 761/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7639 - val_loss: 21.7523\n",
            "Epoch 762/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7645 - val_loss: 21.7509\n",
            "Epoch 763/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7644 - val_loss: 21.7571\n",
            "Epoch 764/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7662 - val_loss: 21.7621\n",
            "Epoch 765/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7641 - val_loss: 21.7573\n",
            "Epoch 766/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7645 - val_loss: 21.7570\n",
            "Epoch 767/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7631 - val_loss: 21.7514\n",
            "Epoch 768/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7640 - val_loss: 21.7491\n",
            "Epoch 769/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7636 - val_loss: 21.7482\n",
            "Epoch 770/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7646 - val_loss: 21.7491\n",
            "Epoch 771/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7428\n",
            "Epoch 772/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7636 - val_loss: 21.7440\n",
            "Epoch 773/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7469\n",
            "Epoch 774/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7643 - val_loss: 21.7475\n",
            "Epoch 775/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7665 - val_loss: 21.7420\n",
            "Epoch 776/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7673 - val_loss: 21.7505\n",
            "Epoch 777/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7509\n",
            "Epoch 778/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7536\n",
            "Epoch 779/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7644 - val_loss: 21.7524\n",
            "Epoch 780/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7649 - val_loss: 21.7516\n",
            "Epoch 781/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7683 - val_loss: 21.7429\n",
            "Epoch 782/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7652 - val_loss: 21.7398\n",
            "Epoch 783/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7439\n",
            "Epoch 784/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7662 - val_loss: 21.7394\n",
            "Epoch 785/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7396\n",
            "Epoch 786/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7636 - val_loss: 21.7371\n",
            "Epoch 787/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7640 - val_loss: 21.7388\n",
            "Epoch 788/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7660 - val_loss: 21.7348\n",
            "Epoch 789/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7662 - val_loss: 21.7414\n",
            "Epoch 790/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7661 - val_loss: 21.7376\n",
            "Epoch 791/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7398\n",
            "Epoch 792/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7646 - val_loss: 21.7416\n",
            "Epoch 793/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7630 - val_loss: 21.7393\n",
            "Epoch 794/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7674 - val_loss: 21.7307\n",
            "Epoch 795/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7656 - val_loss: 21.7348\n",
            "Epoch 796/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7636 - val_loss: 21.7363\n",
            "Epoch 797/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7646 - val_loss: 21.7350\n",
            "Epoch 798/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7639 - val_loss: 21.7386\n",
            "Epoch 799/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7638 - val_loss: 21.7395\n",
            "Epoch 800/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7644 - val_loss: 21.7447\n",
            "Epoch 801/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7643 - val_loss: 21.7457\n",
            "Epoch 802/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7681 - val_loss: 21.7530\n",
            "Epoch 803/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7642 - val_loss: 21.7510\n",
            "Epoch 804/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7640 - val_loss: 21.7468\n",
            "Epoch 805/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7658 - val_loss: 21.7430\n",
            "Epoch 806/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7675 - val_loss: 21.7395\n",
            "Epoch 807/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7630 - val_loss: 21.7422\n",
            "Epoch 808/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7450\n",
            "Epoch 809/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7649 - val_loss: 21.7485\n",
            "Epoch 810/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7478\n",
            "Epoch 811/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7650 - val_loss: 21.7533\n",
            "Epoch 812/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7683 - val_loss: 21.7444\n",
            "Epoch 813/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7682 - val_loss: 21.7487\n",
            "Epoch 814/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7647 - val_loss: 21.7509\n",
            "Epoch 815/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7650 - val_loss: 21.7509\n",
            "Epoch 816/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7647 - val_loss: 21.7454\n",
            "Epoch 817/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7677 - val_loss: 21.7371\n",
            "Epoch 818/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7647 - val_loss: 21.7400\n",
            "Epoch 819/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7648 - val_loss: 21.7438\n",
            "Epoch 820/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7650 - val_loss: 21.7506\n",
            "Epoch 821/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7527\n",
            "Epoch 822/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7640 - val_loss: 21.7556\n",
            "Epoch 823/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7631 - val_loss: 21.7588\n",
            "Epoch 824/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7597\n",
            "Epoch 825/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7637 - val_loss: 21.7605\n",
            "Epoch 826/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7646 - val_loss: 21.7629\n",
            "Epoch 827/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7652 - val_loss: 21.7662\n",
            "Epoch 828/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7654 - val_loss: 21.7598\n",
            "Epoch 829/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7655 - val_loss: 21.7625\n",
            "Epoch 830/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7650 - val_loss: 21.7543\n",
            "Epoch 831/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7629 - val_loss: 21.7499\n",
            "Epoch 832/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7653 - val_loss: 21.7430\n",
            "Epoch 833/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7660 - val_loss: 21.7412\n",
            "Epoch 834/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 24.7655 - val_loss: 21.7462\n",
            "Epoch 835/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7674 - val_loss: 21.7413\n",
            "Epoch 836/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7633 - val_loss: 21.7449\n",
            "Epoch 837/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7684 - val_loss: 21.7513\n",
            "Epoch 838/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7638 - val_loss: 21.7504\n",
            "Epoch 839/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7638 - val_loss: 21.7483\n",
            "Epoch 840/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7642 - val_loss: 21.7476\n",
            "Epoch 841/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7691 - val_loss: 21.7539\n",
            "Epoch 842/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7632 - val_loss: 21.7560\n",
            "Epoch 843/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7653 - val_loss: 21.7592\n",
            "Epoch 844/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7663 - val_loss: 21.7529\n",
            "Epoch 845/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7644 - val_loss: 21.7568\n",
            "Epoch 846/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7647 - val_loss: 21.7509\n",
            "Epoch 847/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7639 - val_loss: 21.7508\n",
            "Epoch 848/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7497\n",
            "Epoch 849/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7646 - val_loss: 21.7478\n",
            "Epoch 850/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 24.7640 - val_loss: 21.7530\n",
            "Epoch 851/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7531\n",
            "Epoch 852/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7626 - val_loss: 21.7476\n",
            "Epoch 853/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7647 - val_loss: 21.7394\n",
            "Epoch 854/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7660 - val_loss: 21.7285\n",
            "Epoch 855/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7660 - val_loss: 21.7312\n",
            "Epoch 856/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7652 - val_loss: 21.7286\n",
            "Epoch 857/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7662 - val_loss: 21.7229\n",
            "Epoch 858/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7676 - val_loss: 21.7265\n",
            "Epoch 859/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7654 - val_loss: 21.7266\n",
            "Epoch 860/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7662 - val_loss: 21.7207\n",
            "Epoch 861/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7677 - val_loss: 21.7209\n",
            "Epoch 862/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7645 - val_loss: 21.7216\n",
            "Epoch 863/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7649 - val_loss: 21.7212\n",
            "Epoch 864/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7657 - val_loss: 21.7207\n",
            "Epoch 865/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7648 - val_loss: 21.7178\n",
            "Epoch 866/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7670 - val_loss: 21.7150\n",
            "Epoch 867/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7663 - val_loss: 21.7165\n",
            "Epoch 868/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7698 - val_loss: 21.7133\n",
            "Epoch 869/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7664 - val_loss: 21.7249\n",
            "Epoch 870/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7272\n",
            "Epoch 871/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7639 - val_loss: 21.7335\n",
            "Epoch 872/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7337\n",
            "Epoch 873/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7380\n",
            "Epoch 874/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 24.7635 - val_loss: 21.7392\n",
            "Epoch 875/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7439\n",
            "Epoch 876/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7655 - val_loss: 21.7483\n",
            "Epoch 877/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7644 - val_loss: 21.7504\n",
            "Epoch 878/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7504\n",
            "Epoch 879/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7513\n",
            "Epoch 880/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7667 - val_loss: 21.7509\n",
            "Epoch 881/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7475\n",
            "Epoch 882/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7643 - val_loss: 21.7480\n",
            "Epoch 883/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7491\n",
            "Epoch 884/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7629 - val_loss: 21.7556\n",
            "Epoch 885/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7651 - val_loss: 21.7640\n",
            "Epoch 886/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7666 - val_loss: 21.7665\n",
            "Epoch 887/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7648 - val_loss: 21.7640\n",
            "Epoch 888/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7646 - val_loss: 21.7637\n",
            "Epoch 889/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7641 - val_loss: 21.7713\n",
            "Epoch 890/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7644 - val_loss: 21.7731\n",
            "Epoch 891/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7652 - val_loss: 21.7682\n",
            "Epoch 892/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7663 - val_loss: 21.7710\n",
            "Epoch 893/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7644 - val_loss: 21.7675\n",
            "Epoch 894/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7649 - val_loss: 21.7636\n",
            "Epoch 895/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7641 - val_loss: 21.7649\n",
            "Epoch 896/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7685 - val_loss: 21.7558\n",
            "Epoch 897/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7647 - val_loss: 21.7592\n",
            "Epoch 898/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7660 - val_loss: 21.7587\n",
            "Epoch 899/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7635 - val_loss: 21.7651\n",
            "Epoch 900/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7691 - val_loss: 21.7726\n",
            "Epoch 901/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7675 - val_loss: 21.7717\n",
            "Epoch 902/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7715 - val_loss: 21.7601\n",
            "Epoch 903/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7665 - val_loss: 21.7658\n",
            "Epoch 904/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7651 - val_loss: 21.7670\n",
            "Epoch 905/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7641 - val_loss: 21.7631\n",
            "Epoch 906/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7648 - val_loss: 21.7612\n",
            "Epoch 907/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7633 - val_loss: 21.7547\n",
            "Epoch 908/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7651 - val_loss: 21.7546\n",
            "Epoch 909/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7627 - val_loss: 21.7490\n",
            "Epoch 910/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7631 - val_loss: 21.7471\n",
            "Epoch 911/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7648 - val_loss: 21.7398\n",
            "Epoch 912/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7656 - val_loss: 21.7405\n",
            "Epoch 913/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7637 - val_loss: 21.7443\n",
            "Epoch 914/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7640 - val_loss: 21.7502\n",
            "Epoch 915/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7486\n",
            "Epoch 916/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7635 - val_loss: 21.7496\n",
            "Epoch 917/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7637 - val_loss: 21.7488\n",
            "Epoch 918/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7672 - val_loss: 21.7507\n",
            "Epoch 919/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7653 - val_loss: 21.7519\n",
            "Epoch 920/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7634 - val_loss: 21.7482\n",
            "Epoch 921/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7500\n",
            "Epoch 922/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7677 - val_loss: 21.7465\n",
            "Epoch 923/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7639 - val_loss: 21.7465\n",
            "Epoch 924/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7669 - val_loss: 21.7541\n",
            "Epoch 925/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7640 - val_loss: 21.7600\n",
            "Epoch 926/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7664 - val_loss: 21.7662\n",
            "Epoch 927/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7661 - val_loss: 21.7745\n",
            "Epoch 928/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7668 - val_loss: 21.7724\n",
            "Epoch 929/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7644 - val_loss: 21.7674\n",
            "Epoch 930/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7649 - val_loss: 21.7680\n",
            "Epoch 931/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7659 - val_loss: 21.7644\n",
            "Epoch 932/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7633 - val_loss: 21.7557\n",
            "Epoch 933/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7645 - val_loss: 21.7525\n",
            "Epoch 934/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7656 - val_loss: 21.7535\n",
            "Epoch 935/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7633 - val_loss: 21.7445\n",
            "Epoch 936/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7630 - val_loss: 21.7376\n",
            "Epoch 937/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7644 - val_loss: 21.7387\n",
            "Epoch 938/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7820 - val_loss: 21.7258\n",
            "Epoch 939/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7633 - val_loss: 21.7323\n",
            "Epoch 940/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7686 - val_loss: 21.7437\n",
            "Epoch 941/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7649 - val_loss: 21.7450\n",
            "Epoch 942/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7634 - val_loss: 21.7445\n",
            "Epoch 943/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7636 - val_loss: 21.7420\n",
            "Epoch 944/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7635 - val_loss: 21.7412\n",
            "Epoch 945/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 24.7649 - val_loss: 21.7347\n",
            "Epoch 946/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7655 - val_loss: 21.7370\n",
            "Epoch 947/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7646 - val_loss: 21.7375\n",
            "Epoch 948/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7636 - val_loss: 21.7340\n",
            "Epoch 949/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7647 - val_loss: 21.7302\n",
            "Epoch 950/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7639 - val_loss: 21.7310\n",
            "Epoch 951/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7704 - val_loss: 21.7259\n",
            "Epoch 952/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7652 - val_loss: 21.7248\n",
            "Epoch 953/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7647 - val_loss: 21.7268\n",
            "Epoch 954/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7664 - val_loss: 21.7222\n",
            "Epoch 955/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7660 - val_loss: 21.7245\n",
            "Epoch 956/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7654 - val_loss: 21.7294\n",
            "Epoch 957/1000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 24.7649 - val_loss: 21.7274\n",
            "Epoch 958/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7656 - val_loss: 21.7291\n",
            "Epoch 959/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7696 - val_loss: 21.7193\n",
            "Epoch 960/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7654 - val_loss: 21.7190\n",
            "Epoch 961/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7658 - val_loss: 21.7218\n",
            "Epoch 962/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7683 - val_loss: 21.7282\n",
            "Epoch 963/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7645 - val_loss: 21.7275\n",
            "Epoch 964/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7645 - val_loss: 21.7278\n",
            "Epoch 965/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7655 - val_loss: 21.7266\n",
            "Epoch 966/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 24.7644 - val_loss: 21.7298\n",
            "Epoch 967/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7641 - val_loss: 21.7306\n",
            "Epoch 968/1000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 24.7651 - val_loss: 21.7366\n",
            "Epoch 969/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7671 - val_loss: 21.7338\n",
            "Epoch 970/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7637 - val_loss: 21.7384\n",
            "Epoch 971/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7667 - val_loss: 21.7507\n",
            "Epoch 972/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7646 - val_loss: 21.7533\n",
            "Epoch 973/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7647 - val_loss: 21.7544\n",
            "Epoch 974/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7637 - val_loss: 21.7503\n",
            "Epoch 975/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7636 - val_loss: 21.7456\n",
            "Epoch 976/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7677 - val_loss: 21.7391\n",
            "Epoch 977/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7639 - val_loss: 21.7405\n",
            "Epoch 978/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7634 - val_loss: 21.7432\n",
            "Epoch 979/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7647 - val_loss: 21.7488\n",
            "Epoch 980/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7642 - val_loss: 21.7456\n",
            "Epoch 981/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7664 - val_loss: 21.7489\n",
            "Epoch 982/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7639 - val_loss: 21.7484\n",
            "Epoch 983/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7633 - val_loss: 21.7443\n",
            "Epoch 984/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7684 - val_loss: 21.7380\n",
            "Epoch 985/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7647 - val_loss: 21.7442\n",
            "Epoch 986/1000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 24.7641 - val_loss: 21.7443\n",
            "Epoch 987/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7708 - val_loss: 21.7394\n",
            "Epoch 988/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7676 - val_loss: 21.7557\n",
            "Epoch 989/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7643 - val_loss: 21.7571\n",
            "Epoch 990/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7653 - val_loss: 21.7620\n",
            "Epoch 991/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7648 - val_loss: 21.7600\n",
            "Epoch 992/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7648 - val_loss: 21.7643\n",
            "Epoch 993/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7646 - val_loss: 21.7653\n",
            "Epoch 994/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7660 - val_loss: 21.7717\n",
            "Epoch 995/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7650 - val_loss: 21.7688\n",
            "Epoch 996/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7663 - val_loss: 21.7735\n",
            "Epoch 997/1000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 24.7668 - val_loss: 21.7659\n",
            "Epoch 998/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7644 - val_loss: 21.7673\n",
            "Epoch 999/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 24.7668 - val_loss: 21.7682\n",
            "Epoch 1000/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 24.7650 - val_loss: 21.7707\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d967a1b10>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    }
  ]
}